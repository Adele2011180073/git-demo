# git-demo
demo for the usage of GitHub
1.LR损失函数
LR损失函数叫最大似然损失函数（交叉熵）
2.常见损失函数：
（1）Zero-one Loss (0-1损失)
（2）Perceptron Loss(感知损失)
（3）Hinge Loss (合页损失)
（4）交叉熵损失函数
（5）平方误差损失函数
（6）Absolute Loss
 (7)Expotensial Loss(指数误差)
 3.过拟合
 过拟合（overfitting）是指在模型参数拟合过程中的问题，由于训练数据包含抽样误差，训练时，复杂的模型将抽样误差也考虑在内，将抽样误差也进行了很好的拟合。
 具体表现就是最终模型在训练集上效果好；在测试集上效果差。模型泛化能力弱。
 
 为什么？
 
 为什么要解决过拟合现象？这是因为我们拟合的模型一般是用来预测未知的结果（不在训练集内），过拟合虽然在训练集上效果好，但是在实际使用时（测试集）效果差。同时，在很多问题上，我们无法穷尽所有状态，不可能将所有情况都包含在训练集上。所以，必须要解决过拟合问题。
 
 为什么在机器学习中比较常见？这是因为机器学习算法为了满足尽可能复杂的任务，其模型的拟合能力一般远远高于问题复杂度，也就是说，机器学习算法有「拟合出正确规则的前提下，进一步拟合噪声」的能力。
 
 而传统的函数拟合问题（如机器人系统辨识），一般都是通过经验、物理、数学等推导出一个含参模型，模型复杂度确定了，只需要调整个别参数即可。模型「无多余能力」拟合噪声。
 4.防止过拟合
 （1）获取更多数据 ：
    a.从数据源头获取更多数据
    b.根据当前数据集估计数据分布参数，使用该分布产生更多数据
    c.数据增强（Data Augmentation）：通过一定规则扩充数据。
 （2）使用合适的模型
    a.网络结构
    b.训练时间
    c.限制权值
    d.增加噪声
  (3)结合多种模型
     a.bagging
     b.boosting
     c.dropout
  （4）贝叶斯方法
  5.防止梯度消失的方法
     a.预训练加微调
     b.梯度剪切、权重正则（针对梯度爆炸）
     c.使用不同的激活函数
     d.使用batchnorm
     e.使用残差结构
     f.使用LSTM网络
    
 
